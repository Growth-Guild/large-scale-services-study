# 1주차
> p28 강의 4 ~ p78 강의 9

---
### 강의 4. 하테나 북마크의 데이터 규모
+ 기가 바이트 이상의 같은 대규모 데이터는 처리하는데 많은 시간이 걸린다.
  + 인덱스나 쿼리 작성에 유의가 필요하다.
  + 기가 < 테라 < 페타 < 엑사 < 제타 < 요타


+ 시행착오로 기본적인 사항은 파악해두고 문제가 생겼을 때 해결할 수 있는 능력을 기르자!

---
### 강의 5. 대규모 데이터 처리의 어려운 점
+ 대규모 데이터는 메모리 내 계산이 어려워 디스크를 두고 특정 데이터를 검색하게 된다.


+ 메모리와 디스크
    1. 탐색속도의 차이 
        + 메모리는 디스크보다 10<sup>5</sup> ~ 10<sup>6</sup> 배 이상 탐색속도가 빠르다.
        + 디스크는 헤드의 이동, 원반의 회전의 물리적 동작이 수반되기 때문.
        + 메모리상의 데이터가 CPU 캐시에 올리기 쉬운 알고리즘이나 데이터 구조라면 탐색속도는 더 빨라진다.
        + OS는 연속된 데이터를 같은 위치에 쌓아 디스크 탐색속도를 보완한다.
    2. 전송속도의 차이 
        + 전송속도에서도 100배 이상의 차이가 난다. (Linux hdparm)
        + SSD는 탐색은 빠르지만 버스 속도가 병목이 되거나 그 밖에 구조에 기인하는 면이 있어 메모리만큼의 속도가 나오지 않는다.
    3. 확장성의 문제를 고려하자!
    

+ Linux 단일 호스트의 부하
    + "추측하지 말라, 계측하라"
    + 병목 규명작업
        1. Load Average 확인
        2. CPU, I/O 중 병목 원인 조사
            + 별다른 병목이 발생하지 않는 경우로 서버증설이 필요한 경우인지
            + 불필요한 데이터가 있는지
            + I/O 알고리즘으로 성능 개선
    
---
### 강의 6. 규모조정의 요소
+ 규모조정과 확장성
    + 고가 하드웨어의 '스케일업' or 저가 다수의 하드웨어 '스케일아웃'

  
+ 웹 애플리케이션의 부하
    + 프록시 - AP서버(CPU 부하) - DB(I/O부하)
        + CPU 부하는 서버의 확장과 로드밸런서로 해결
        + I/O 부하는 디스크 I/O 부하로 이어지고, DB를 확장하는 것은 어려움이 따른다.
    + 부하를 주는 프로그램 = 바운드한 프로그램
        + 대규모 데이터는 I/O 바운드한 서버이다.
    + 같은 서버라도 부하의 종류가 다르면 그 특성은 크게 달라진다.
 

+ Load Average   
    + 멀티태스킹 OS에서 top의 출력내용에서 CPU 부하와 I/O 부하를 확인할 수 있는 수단.
    + 태스크 대기상태를 확인할 수 있는 값으로 높을수록 부하가 높다.
      + CPU 실행권한이 부여되기를 기다리고 있는 프로세스
      + 디스크 I/O가 완료하기를 기다리고 있는 프로세스
    + 하드웨어가 일정 주기로 CPU에 보내는 Timer Interrupt마다 load average가 계산된다.
    + 구체적인 리소스 위치를 확인할 필요가 있다.

---
### 강의 7. 대규모 데이터를 다루기 위한 기초지식
+ 프로그램을 작성할 때의 요령
    1. 메모리에서 처리하고, 디스크 seek 최소화, 국소성을 활용한 분산
    2. 적합한 알고리즘
    3. 데이터 압축과 정보검색기술(용도에 특화된 검색엔진)
        + 메모리 캐싱
    

+ 병목을 규명하는 방식
    1. load average 확인
    2. sar로 CPU 사용률, I/O 대기율 확인
    3. 메모리 사용률이나 스왑 발생상황, 프로세스 상태 등을 참조
    + 멀티코어에서는 CPU 사용률을 개별적으로 확인할 가치가 있다. 
        + 디스크가 1개인 경우, 멀티 CPU라 하더라도 한 개의 CPU에 부하가 발생하는 편중현상을 나타낼 수 있다.


---
### 강의 8. OS의 캐시 구조
+ I/O 대책에 대한 기반은 OS에 있다.
    + OS는 메모리를 이용해서 디스크 액세스를 줄인다.
    + OS 캐시
        + Linux의 페이지(가상 메모리의 최소단위) 캐시, 버퍼 캐시
        + 파일캐시라는 표현이 적절하지 않은 이유는 OS는 블록단위로 캐싱하기 때문
            + 파일 전체를 읽어도 LRU에 따라 오래된 것이 파기되므로 점점 부하도 낮아진다.
    
+ 가상 메모리 구조
    + 논리적 선형 어드레스를 물리적 어드레스로 변환하는 것이다.
      + 물리적 하드웨어를 OS에서 추상화하기 위해 존재
    + 어드레스 변환의 이점
    + 스왑은 가상 메모리를 응용한 기술로 물리 메모리가 부족한 경우, 2차 기억장치(주로 디스크)를 메모리로 간주하여 외형상 메모리 부족 기능을 해소하는 원리이다.
    + 메모리를 직접 프로세스로 넘기는 것이 아니라 일단 커널 내에서 메모리를 추상화하고 있다.
        + 비어있는 메모리 어드레스를 변환하여 '페이지'를 확보해서 프로세스로 넘긴다.


+ 페이지 캐시
    + 커널이 한 번 할달된 메모리를 해제하지 않고 남겨두는 것.
    + 프로세스는 디스크에 직접 액세스할 수 없기 때문에 디스크 블럭을 읽어와서 메모리에 페이지 캐시를 만들어 프로제스가 액세스할 수 있도록 한다.
    + OS를 계속 가동시켜두면 캐싱이 유지되서 빠르게 엑세스 가능하다.
    

+ VFS 가상파일시스템
    + 디스크를 조작하는 디바이스 드라이버와 OS 사이의 파일시스템이 있고 이 파일시스템 인터페이스를 통일하는 것이 VFS이다.
    + 따라서, 어떤 파일시스템을 읽어내더라도 동일구조로 캐싱된다.
    + 추상화와 페이지 캐시 부분과 연관
    

+ Linux에서의 캐싱
    + 파일의 i노드와 오프셋(식별위치)를 통해 파일 일부를 캐싱한다.
    + 메모리가 비어있으면 전부 캐싱한다. 
        + 메모리가 필요해지면 오래된 캐시를 삭제하고 캐싱
    

+ 메모리 증가로 I/O 부하를 줄일 수 있다.


---
### 강의 9. I/O 부하를 줄이는 방법
1. 캐시를 전제로 한 I/O 줄이는 방법
    1. 물리 메모리가 데이터 규모보다 큰 경우
        + 데이터 압축으로 전부 캐싱
    2. 경제적 비용과의 밸런스 고려
  
  
2. 복수 서버로 확장
    + I/O 분산에는 국소성을 고려한다.
    + 캐싱할 수 없는 비율을 변함없이 그대로 복사되는 형태가 된다.
    + 데이터를 적절하게 분할하여 캐시에 올릴 데이터 비율을 증가시켜 전송량 향상을 기대할 수 있다.
    

    

    
    