# 1주차
- - -
## 강의 4 - 하테나 북마크의 데이터 규모
* 데이터의 규모는 커질 수록 쿼리를 처리하는데 많은 시간이 소요되므로 인덱스를 잘 걸어주어야 한다.
* 데이터의 규모가 너무 거대하여 인덱스를 통해서도 비기능적 요건이 충족되지 않으면 콜드 데이터를 이관하여 분리 보관 하거나, 샤딩을 고려해봐도 좋을 것 같다.
* 크고 작은 문제들에 대한 해결법을 잘 알고 있는 것은 그만큼 많은 트러블을 접해왔다는 것이다. 문제가 발생하면 시행착오를 거치며 노련하게 경험을 쌓자.

- - -
## 강의 5 - 대규모 데이터 처리의 어려운 점

### 대규모 데이터의 어려운 점
* 메모리 내에서 계산할 수 없기 때문에 지속적으로 디스크에서 읽어야 한다.
* 디스크는 메모리에 비해서 상당히 느리다.
* 메모리는 디스크보다 10^5 ~ 10^6 배 이상 빠르다.

### 디스크는 왜 느린가
* 메모리는 전기적인 부품이므로 물리적 구조는 탐색속도와 그다지 관계가 없다.
* 디스크는 동축 상에 원반에 쌓여있고, 데이터를 읽기 위해서는 메모리와 달리 회전 등의 물리적인 동작을 수반한다. 이러한 물리적인 구조가 탐색 속도에 영향을 준다.

### OS 레벨에서 속도 차이를 줄이는 방법
* 디스크는 속도가 느리지만 OS는 이러한 점을 커버하기 위해 연속된 데이터를 같은 위치에 쌓는다.
* 같은 위치에 쌓인 데이터들은 읽을 때 한꺼번에 읽도록 하여 1번의 디스크 회전만으로 읽는 데이터 수를 늘려서 회전 수를 최소화할 수 있다.
* 그렇다고해서 메모리와의 속도차를 극복할 수 있는 수준은 아니다.

### 전송속도, 버스의 속도차
* 데이터를 읽고나면 어딘가로 전송을 하게 되는데, 이 전송하는 구간을 버스라고 한다.
* 전송속도는 디스크에서 메모리로 보내거나 메모리에서 CPU로 보내는 등 컴퓨터 내부에서 전송하기 위한 속도이다.
* hdparm 이라는 Linux 툴을 사용하면 그 속도차를 알 수 있는데, "Timing cached reads" 는 메모리에 있는 캐시 데이터의 전송속도를 나타내고, "Timing buffered disk reads" 는 디스크의 전송속도이다.
* 메모리와 CPU는 상당히 빠른 버스로 연결되어 있고, 디스크는 상대적으로 속도가 느리다.

### 병목을 구명하기위한 작업

#### Load Average 확인
* Load Average 는 시스템 전체의 부하상황을 나타내는 지표이다. 
* top 이나 uptime 등의 명령으로 Load Average 를 확인할 수 있다.

#### CPU, I/O 중 병목 원인 조사
* Load Average 가 높은 경우, CPU 와 I/O 어느 쪽에 원인이 있는지를 조사한다.
* sar 이나 vmstat 로 시간 경과에 따라 CPU 사용률이나 I/O 대기율의 추이를 확인할 수 있으므로 이를 참고하여 규명한다.

- - -
## 강의 6 - 규모 조정의 요소

### 규모조정, 확장성
* 웹서비스에서는 고가의 빠른 하드웨어로 교체하여 성능을 끌어올리는 스케일업(Scale-up) 전략보다는 저가이면서 보통 성능의 하드웨어를 여러 개 사영하여 시스템의 전체 성능을 올리는 스케일 아웃(Scale-out) 전략을 많이 사용한다.
* 스케일 아웃은 비용이 저렴하고 시스템 구성에 유연성이 있다는 장점이 있다.
* 하드웨어의 가격이 10배 비싸다고 성능도 10배로 좋은 것은 아니므로 적절한 비용을 산정하여 서버를 구축해야한다.
  * (클라우드 서비스를 사용할 수 있는 환경이라면 그게 제일 좋은 것 같다..)

### 규모조정의 요소
* 애플리케이션 서버에서는 CPU 부하만 소요되고, DB 서버 측면에서는 I/O 부하가 걸린다.
  * 단편적으로는 어느정도 맞는 말이지만, 블로킹 방식의 애플리케이션 서버에서는 CPU 부하 뿐만 아니라 대외 서버, DB 로부터 응답을 기다릴 때 네트워크 I/O 도 발생한다.
* 애플리케이션 서버는 CPU 부하만 발생하므로 데이터를 분산하여 가지고 있는 것이 아니기 때문에 수평 확장이 용이하다.
* 데이터베이스는 데이터를 Read/Write 하므로 수평 확장하여 분산 저장을 하면 두 데이터베이스간에 데이터 동기화 이슈가 발생한다.
  * Read 는 Master-Slave 구조로 복제를 하면 되지만, 멀티소스로 두 곳에서 동시에 Write 하는 경우에는 조금 더 복잡한 토폴로지를 구성해야한다.
  * (역시 클라우드를 쓸 수 있다면 편리하게 클라우드를 사용하자!)

### DB 확장성 확보의 어려움
* DB 에서 많은 부하가 발생하면 디스크를 읽고 쓰기가 느린 특성상 병목이 발생할 수 있고, 이런 상황에서는 애플리케이션 서버를 늘리기만 한다고해서 해결할 수 없다.
* 캐시를 적절하게 이용하면 이에 대한 부담을 줄일 수 있다.
* 하지만 캐시를 이용한다면 캐시의 신선도와 최신화된 DB 데이터와 동기화하는 이슈가 발생하므로 적절하게 Evict 하는 정책을 세워야한다.

### 멀티태스킹 OS 와 부하
* 멀티태스킹 환경에서 여러 태스크를 유한한 하드웨어로 처리하는데, 태스크의 수가 많아지면 매우 짧은 시간 간격으로 여러 태스크들을 전환해가며 처리한다.
  * 태스크들을 전환해가며 처리하는 것을 컨텍스트 스위칭이라고 하며, 스위칭이 빈번해지면 대기 시간이 그만큼 증가한다.
* top 명령어의 출력 내용에는 Load Average(평균 부하) 라는 수치가 포함되어 있다.
  * ex) load average: 0.70, 0.66, 0.59
  * 왼쪽부터 차례대로 1분, 5분, 15분 동안에 단위 시간당 대기된 태스크의 수를 나타낸다. 즉, 평균적으로 어느 저옫의 태스크가 대기 상태로 있었는지를 보고하는 수치이다.

### Average 가 보고하는 부하의 정체
* 하드웨어는 일정 주기로 CPU 로 인터럽트(interrupt)라고 하는 신호를 보낸다. 주기적으로 보내지는 신호라는 점에서 타이머 인터럽트(Timer Interrupt) 라고 한다.
* 이 인터럽트마다 CPU 는 시간을 진행시키거나 실행 중인 프로세스가 CPU 를 얼마나 사용했는지를 계산하는 등 시간에 관련된 처리를 수행한다. 이때 타이머 인터럽트마다 Load Average 가 계산된다.
