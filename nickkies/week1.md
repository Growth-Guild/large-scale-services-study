# 1주차

---
## 1장. OT

> 하테나 서비스
> 
> - 주로 블로그 웹 서비스
> 
> 하테나 규모 
>
> - 사용자 100만명, 
> - 수십 억 액세스/월
> - 하드웨어 서버 500대 이상
> 
> 성장 전략
> - 미니멈 스타트

## 2장. 대규모 데이터 처리 입문

> 1. 대규모 데이터 탐색 속도에 영향을 주는 요인
>
>> 메모리와 디스크
>> 
>> - 대용량 데이터는 메모리 내에서 계산할 수 없고 디스크를 사용해야한다.
>> 
>> - 메모리의 탐색 속도는 디스크의 탐색속도 보다 10^5 ~ 10^6배 빠르다.
>>
>> - 메모리의 전송 속도는 디스크의 전송속도 보다 100배 이상 빠르다.
>
> 2. 규모조정
>
>> scale-up: 하드웨어의 성능을 높힘 (I/O 부하)
>>
>> scale-out: 하드웨어를 많이 나열해서 서능을 높힘 (CPU 부하)

## 3장. OS 캐시와 분산
> 1. OS의 캐시 구조
> 
>> 메모리 구조
>>
>> - 디스크 
>> 
>> - 메모리
>> 
>> - 캐시
>> 
>> 캐싱
>> 
>> - 블록 단위로 캐싱(VFS)
>> 
>> - 최신 데이터가 캐싱(LRU) -> 많이 사용할 수록 최적화 되어감 
>>
>> top 만쓰지 말고 sar로 메모리 상태를 확인해 보자 (sysstat package)
> 
> 2. I/O 부하를 줄이는 방법
>
>> scale-out 전략만으로는 부하를 줄일 수 없다.
>> 
>> -> 캐싱할 수 없는 비율은 변하지 않기 때문에 병목현상 발생! 
 